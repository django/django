package llm

import (
	"bytes"
	"code-review/backend/internal/models"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"
	"unicode/utf8"
)

const (
	// FIX #2: Use valid Gemini model name
	geminiModel = "gemini-2.5-flash" // Changed from "gemini-3-flash-preview"
	geminiURL   = "https://generativelanguage.googleapis.com/v1beta/models/" + geminiModel + ":generateContent"
)

// FIX #4: Safe UTF-8 truncation helper
func truncateUTF8(s string, maxBytes int) string {
	if len(s) <= maxBytes {
		return s
	}

	fmt.Printf("[WARNING] Context truncation triggered! Input size: %d bytes, Max allowed: %d bytes\n", len(s), maxBytes)

	// Find the last valid UTF-8 character boundary before maxBytes
	truncated := s[:maxBytes]

	// Walk backwards to find a valid UTF-8 boundary
	for len(truncated) > 0 {
		if utf8.ValidString(truncated) {
			return truncated + "\n...[TRUNCATED]..."
		}
		// Remove one byte and try again
		truncated = truncated[:len(truncated)-1]
	}

	return "\n...[TRUNCATED]..."
}

// isDocumentationFile checks if a file is documentation/config and shouldn't be reviewed
func isDocumentationFile(path string) bool {
	lowerPath := strings.ToLower(path)
	baseName := strings.ToLower(filepath.Base(path))

	// Documentation file extensions
	docExtensions := []string{".md", ".txt", ".rst", ".adoc"}
	for _, ext := range docExtensions {
		if strings.HasSuffix(lowerPath, ext) {
			return true
		}
	}

	// FIX #3: More precise matching for common doc filenames
	// Use exact match or match with common doc extensions
	docFilePatterns := []string{
		"readme", "license", "changelog", "contributing",
		"code_of_conduct", "authors", "contributors",
		"history", "news", "thanks", "acknowledgments",
	}

	// Extract base name without extension for comparison
	baseWithoutExt := baseName
	for _, ext := range docExtensions {
		baseWithoutExt = strings.TrimSuffix(baseWithoutExt, ext)
	}

	// Check for exact match (e.g., "readme", "todo")
	for _, docPattern := range docFilePatterns {
		if baseWithoutExt == docPattern {
			return true
		}
	}

	// Special case: also check if filename is just the pattern (e.g., "README", "TODO", "LICENSE")
	for _, docPattern := range docFilePatterns {
		if baseName == docPattern {
			return true
		}
	}

	// Configuration/metadata files (no code logic to review)
	configFiles := []string{
		".gitignore", ".dockerignore", ".editorconfig", ".env.example",
		"makefile", ".prettierrc", ".eslintrc",
		"tsconfig.json", "package.json", "package-lock.json",
		"go.mod", "go.sum", "requirements.txt", "pipfile",
		"poetry.lock", "yarn.lock", "composer.json",
	}

	for _, configFile := range configFiles {
		if strings.Contains(lowerPath, configFile) {
			return true
		}
	}

	return false
}

// filterReviewableFiles removes documentation and config files from the map
func filterReviewableFiles(files map[string]string) map[string]string {
	filtered := make(map[string]string)
	for path, content := range files {
		if !isDocumentationFile(path) {
			filtered[path] = content
		}
	}
	return filtered
}

// FIX #1: Improved diff path extraction using regex
var diffPathRegex = regexp.MustCompile(`^diff --git a/(.*) b/(.*)$`)

// extractChangedLinesFromDiff extracts only the changed lines with their context
// Returns a map of file -> list of changed line sections
func extractChangedLinesFromDiff(diff string) map[string][]string {
	result := make(map[string][]string)
	lines := strings.Split(diff, "\n")

	var currentFile string
	var currentSection []string

	for _, line := range lines {
		// File header: diff --git a/file b/file
		if strings.HasPrefix(line, "diff --git") {
			if currentFile != "" && len(currentSection) > 0 {
				result[currentFile] = append(result[currentFile], strings.Join(currentSection, "\n"))
			}
			currentSection = []string{}

			// FIX #1: Use regex to extract filename (handles spaces and quoted paths)
			matches := diffPathRegex.FindStringSubmatch(line)
			if len(matches) >= 3 {
				// Use b/ path (destination), remove quotes if present
				currentFile = strings.Trim(matches[2], "\"")
			} else {
				// Fallback: try to extract using the old method for edge cases
				parts := strings.Fields(line)
				if len(parts) >= 4 {
					currentFile = strings.TrimPrefix(parts[3], "b/")
					currentFile = strings.Trim(currentFile, "\"")
				}
			}
			continue
		}

		// Track hunk headers and changed lines
		if strings.HasPrefix(line, "@@") {
			if len(currentSection) > 0 {
				result[currentFile] = append(result[currentFile], strings.Join(currentSection, "\n"))
			}
			currentSection = []string{line}
		} else if strings.HasPrefix(line, "+") || strings.HasPrefix(line, "-") {
			currentSection = append(currentSection, line)
		} else if len(currentSection) > 0 && !strings.HasPrefix(line, "\\") {
			// Context line within a hunk
			currentSection = append(currentSection, line)
		}
	}

	// Add final section
	if currentFile != "" && len(currentSection) > 0 {
		result[currentFile] = append(result[currentFile], strings.Join(currentSection, "\n"))
	}

	return result
}

// RunReview analyzes the diff using the provided API key, settings, and PR context.
func RunReview(ctx context.Context, client *http.Client, diff string, changedFiles map[string]string, dependencies map[string]string, settings models.RepoSettings, repoStructure string, apiKey string, prContext models.PRContext) (*models.ReviewResult, error) {
	// Filter out documentation files
	reviewableFiles := filterReviewableFiles(changedFiles)
	reviewableDeps := filterReviewableFiles(dependencies)

	if len(reviewableFiles) == 0 {
		return &models.ReviewResult{
			Summary:  "No reviewable code files changed (only documentation/config files)",
			Comments: []models.ReviewComment{},
		}, nil
	}

	// 1. Construct Prompt
	prompt := buildPrompt(diff, reviewableFiles, reviewableDeps, settings, repoStructure, prContext)

	// LOGGING: Detailed context summary as requested
	fmt.Println("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("ğŸ§  [LLM INPUT] Context Summary & Code Graph Contributions")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

	fmt.Printf("ğŸ“‚ Changed Files (%d):\n", len(reviewableFiles))
	for _, path := range getFileKeys(reviewableFiles) {
		fmt.Printf("  - %s\n", path)
	}

	fmt.Printf("\nğŸ” Code Graph Summaries (%d):\n", len(reviewableDeps))
	for _, path := range getFileKeys(reviewableDeps) {
		content := reviewableDeps[path]
		fmt.Printf("  + File: %s (%d chars)\n", path, len(content))
		fmt.Println("    --- START SUMMARY ---")
		fmt.Println(content)
		fmt.Println("    --- END SUMMARY ---")
	}

	fmt.Printf("\nğŸ“Š Meta Context:\n")
	fmt.Printf("  - Repository Structure: %d chars\n", len(repoStructure))
	fmt.Printf("  - PR Intent Context:   %d chars\n", len(buildPRContextSummary(prContext)))
	fmt.Printf("  - Total Prompt Size:   %d chars\n", len(prompt))
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// 2. Prepare Request
	reqBody := map[string]interface{}{
		"contents": []map[string]interface{}{
			{
				"parts": []map[string]string{
					{"text": prompt},
				},
			},
		},
		"generationConfig": map[string]interface{}{
			"responseMimeType": "application/json",
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %v", err)
	}

	url := fmt.Sprintf("%s?key=%s", geminiURL, apiKey)
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %v", err)
	}
	req.Header.Set("Content-Type", "application/json")

	// 3. Execute Request
	if client == nil {
		client = &http.Client{Timeout: 60 * time.Second}
	}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("LLM request failed: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("LLM returned status %d: %s", resp.StatusCode, string(body))
	}

	// 4. Parse Response
	var geminiResp struct {
		Candidates []struct {
			Content struct {
				Parts []struct {
					Text string `json:"text"`
				} `json:"parts"`
			} `json:"content"`
		} `json:"candidates"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&geminiResp); err != nil {
		return nil, fmt.Errorf("failed to decode LLM response: %v", err)
	}

	if len(geminiResp.Candidates) == 0 || len(geminiResp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("LLM returned empty response")
	}

	responseText := geminiResp.Candidates[0].Content.Parts[0].Text

	// Robust parsing: try Result object first, then fallback to Array of comments
	var result models.ReviewResult
	if err := json.Unmarshal([]byte(responseText), &result); err != nil {
		// Fallback: Check if it's a naked array of comments
		var comments []models.ReviewComment
		if errArray := json.Unmarshal([]byte(responseText), &comments); errArray == nil {
			result.Comments = comments
			result.Summary = "Automated review comments"
		} else {
			return nil, fmt.Errorf("failed to unmarshal JSON content: %v | content: %s", err, responseText)
		}
	}

	return &result, nil
}

func getFileKeys(m map[string]string) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	return keys
}

func buildPrompt(diff string, changedFiles map[string]string, dependencies map[string]string, settings models.RepoSettings, repoStructure string, prContext models.PRContext) string {
	// Context Window Management
	// Priority order: Changed Files (highest) > Dependencies > Repo Structure (lowest)
	// When over budget, drop the LARGEST dependency files first â€” never cut mid-file.
	// Budget: 720K chars â‰ˆ 180K tokens, aligned with chunker's DefaultTokenBudget
	const MaxContextChars = 720_000

	// Helper to format changed files with FULL context + line numbers.
	formatFilesWithDiff := func(files map[string]string, diffMap map[string][]string) string {
		var b strings.Builder
		for _, path := range getFileKeys(files) {
			content := files[path]
			b.WriteString("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
			b.WriteString(fmt.Sprintf("FILE: %s (Full Content with Line Numbers)\n", path))
			b.WriteString("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

			// Add full content with line numbers
			lines := strings.Split(content, "\n")
			for i, line := range lines {
				b.WriteString(fmt.Sprintf("%d: %s\n", i+1, line))
			}

			// Add diff hunks for focus
			if diffSections, hasDiff := diffMap[path]; hasDiff && len(diffSections) > 0 {
				b.WriteString("\n--------------------------------------------------------------------------------\n")
				b.WriteString(fmt.Sprintf("RECENT CHANGES IN: %s\n", path))
				b.WriteString("--------------------------------------------------------------------------------\n")
				for i, section := range diffSections {
					b.WriteString(fmt.Sprintf("/* Change Block %d:\n%s\n*/\n\n", i+1, section))
				}
			}
		}
		return b.String()
	}

	// Extract changed lines from diff
	diffMap := extractChangedLinesFromDiff(diff)

	// Build annotated changed files section (always included in full â€” highest priority)
	currentSize := 0
	changedContent := formatFilesWithDiff(changedFiles, diffMap)
	currentSize += len(changedContent)

	// Priority-based dependency inclusion:
	// Include deps by ascending size (smallest first). When budget is exhausted,
	// drop remaining deps instead of cutting mid-file.
	type depEntry struct {
		Path    string
		Content string
		Size    int
	}

	depKeys := getFileKeys(dependencies)
	depEntries := make([]depEntry, 0, len(depKeys))
	for _, path := range depKeys {
		formatted := fmt.Sprintf("\n--- FILE: %s ---\n%s\n", path, dependencies[path])
		depEntries = append(depEntries, depEntry{Path: path, Content: formatted, Size: len(formatted)})
	}

	// Sort by size ascending â€” smallest (most critical / compact) deps survive
	sort.Slice(depEntries, func(i, j int) bool {
		return depEntries[i].Size < depEntries[j].Size
	})

	var depsBuilder strings.Builder
	var droppedDeps []string
	for _, dep := range depEntries {
		if currentSize+dep.Size > MaxContextChars {
			droppedDeps = append(droppedDeps, dep.Path)
			continue
		}
		depsBuilder.WriteString(dep.Content)
		currentSize += dep.Size
	}
	depsContent := depsBuilder.String()

	if len(droppedDeps) > 0 {
		fmt.Printf("âš ï¸  [Context Budget] Dropped %d large dependency files to fit within %dK token limit:\n", len(droppedDeps), MaxContextChars/4/1000)
		for _, d := range droppedDeps {
			fmt.Printf("    - %s\n", d)
		}
	}

	// Repo structure (lowest priority â€” truncate or omit if needed)
	if currentSize+len(repoStructure) > MaxContextChars {
		available := MaxContextChars - currentSize
		if available > 1000 { // Only include if there's meaningful space
			repoStructure = truncateUTF8(repoStructure, available)
			fmt.Printf("âš ï¸  [Context Budget] Repo structure truncated to %d chars\n", available)
		} else {
			repoStructure = ""
			fmt.Println("âš ï¸  [Context Budget] Repo structure omitted (no space)")
		}
	}

	var layers = []string{}
	if settings.SecurityEnabled {
		layers = append(layers, "Security (vulnerabilities, secrets, unsafe operations)")
	}
	if settings.BugEnabled {
		layers = append(layers, "Bugs (logic errors, crashes, data corruption)")
	}
	if settings.LintEnabled {
		layers = append(layers, "Lint (style, formatting, best practices)")
	}
	if settings.PerformanceEnabled {
		layers = append(layers, "Performance (inefficiencies, memory leaks, algorithmic issues)")
	}
	if settings.ArchitectureEnabled {
		layers = append(layers, "Architecture (design patterns, structure, maintainability)")
	}

	// Build PR context section with clear intent guidance
	var prContextSection string
	if prContext.Title != "" || prContext.Body != "" || len(prContext.CommitMessages) > 0 {
		prContextSection = `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PR CONTEXT (Developer Intent - Use as Background Only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
This section provides the developer's stated intent. Your review must be based on
the ACTUAL CODE CHANGES, not on whether the code matches the stated intent.

**IMPORTANT DISTINCTIONS:**
- If developer says "added logging for debugging" â†’ This is INTENT, not a defect
- If the logging code actually exposes sensitive data â†’ This IS a defect (review it)
- If developer says "fixed bug X" but code still has bug Y â†’ Review bug Y
- If developer says "temporary change" but code has security flaw â†’ Review the flaw

**USE THIS CONTEXT TO:**
âœ“ Understand what the developer was trying to accomplish
âœ“ Distinguish between intentional debugging code vs accidental security issues
âœ“ Recognize temporary/experimental code (but still flag genuine issues in it)
âœ“ Understand business logic context for the changes

**DO NOT USE THIS CONTEXT TO:**
âœ— Assume code is correct because it matches the description
âœ— Skip reviewing code that's marked as "debug", "temp", or "testing"
âœ— Flag intentional debugging/logging as issues UNLESS it has actual security implications
âœ— Treat the PR description as source of truth for correctness

`
		if prContext.Title != "" {
			prContextSection += fmt.Sprintf("**PR Title:** %s\n", prContext.Title)
		}
		if prContext.Body != "" {
			body := prContext.Body
			if len(body) > 1000 {
				body = truncateUTF8(body, 1000)
			}
			prContextSection += fmt.Sprintf("**PR Description:** %s\n", body)
		}
		if len(prContext.CommitMessages) > 0 {
			prContextSection += "\n**Commit Messages (last 10):**\n"
			msgs := prContext.CommitMessages
			if len(msgs) > 10 {
				msgs = msgs[len(msgs)-10:]
			}
			for _, msg := range msgs {
				prContextSection += fmt.Sprintf("  â€¢ %s\n", msg)
			}
		}
		prContextSection += "\n"
	}

	return fmt.Sprintf(`You are an automated code defect detection system performing static analysis on code changes.
Your SOLE objective is to identify defects, vulnerabilities, bugs, and code quality issues.

%s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PRIMARY ANALYSIS TARGET: Changed Code Files
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Below are the changed files with their import headers and diff hunks showing
exactly what changed. Focus your analysis on the CHANGED SECTIONS marked in comments.

The import/package header helps you understand:
- What packages and types are imported
- The language and module context

The diff hunks show exactly what was added (+) and removed (-).

%s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SUPPORTING CONTEXT: Code Graph (Relationships + Behavioral Summaries)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
%s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SUPPORTING CONTEXT: Repository Structure (For Architecture Analysis)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
%s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ACTIVE DETECTION LAYERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
%v

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MANDATORY ANALYSIS RULES - STRICT COMPLIANCE REQUIRED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RULE 1 - FOCUS ON ACTUAL CODE CHANGES:
  âœ“ Analyze ONLY the code within "Change Block" sections (marked in comments above)
  âœ“ Each comment MUST reference a specific line number from the '+' (added/modified) lines in the diff
  âœ“ If you identify a general problem in a block, tag it on the first relevant '+' line of that block
  âœ“ Use the complete file content to understand context, but flag issues only in changes
  âœ— NEVER comment on unchanged code or line numbers outside the provided change blocks
  âœ— NEVER placeholder line numbers like 0 or 1 unless it is a file-level architectural issue

RULE 2 - CRITICAL ISSUES IN CONTEXT:
  âœ“ IF you find a CRITICAL security vulnerability or severe bug in dependency/context files
  âœ“ AND it DIRECTLY impacts or is called by the changed code
  âœ“ THEN report it with: file=<dependency_file>, line=0, message="[CONTEXT] <problem>"
  âœ“ Use ONLY for severity: critical or warning
  âœ— DO NOT use for general suggestions or info-level issues

RULE 3 - DISTINGUISH INTENT FROM DEFECTS:
  âœ“ Read the PR Context to understand what the developer intended to do
  âœ“ If code has "debug", "temp", or "test" comments, recognize these as intentional
  âœ“ BUT still flag genuine security/correctness issues in that code
  
  Examples:
  â€¢ Code: "log.Debug(response)" + PR says "added debug logging"
    â†’ Do NOT flag as security issue (it's intentional debugging)
  
  â€¢ Code: "log.Info(user.Password)" + PR says "improved logging"
    â†’ DO flag as critical security issue (exposing sensitive data is always wrong)
  
  â€¢ Code: "// TODO: add auth" + PR says "temporary endpoint for testing"
    â†’ DO flag missing authentication (being temporary doesn't make it safe)
  
  â€¢ Code: "time.Sleep(5 * time.Second)" + PR says "debugging race condition"
    â†’ Do NOT flag (it's intentional debug code, not a production bug)

RULE 4 - DOCUMENTATION FILES EXCLUSION:
  âœ— DO NOT review documentation files (README, CHANGELOG, .md files, etc.)
  âœ— DO NOT review configuration files (package.json, go.mod, .gitignore, etc.)
  âœ“ These files have been pre-filtered and should not appear in the changed files
  âœ“ Focus only on actual code logic that can have defects

RULE 5 - ZERO FALSE POSITIVES:
  âœ— DO NOT comment on code that is correct, functional, or follows best practices
  âœ— DO NOT provide praise, confirmations, or acknowledgments
  âœ— DO NOT comment on style preferences unless they cause bugs or violate language standards
  âœ— DO NOT provide educational content or alternative implementations
  âœ— DO NOT comment if you cannot identify a concrete, measurable defect
  âœ“ Silence on correct code is EXPECTED and DESIRED

RULE 6 - COMMENT STRUCTURE (Strict Format):
  Format: "<Problem>. <Fix>."
  
  âœ“ CORRECT Examples:
    - "SQL injection via unsanitized input. Use parameterized queries."
    - "Nil pointer dereference if user is nil. Add nil check before user.ID access."
    - "Race condition on shared map access. Protect with mutex or use sync.Map."
    - "Memory leak from unclosed file handle. Add defer file.Close() after error check."
    - "Password logged in plain text. Remove sensitive data from logs or redact it."
  
  âœ— INCORRECT Examples:
    - "This is good code" (praise - forbidden)
    - "Logging full response might be risky" (vague - not specific enough)
    - "Consider using a different pattern" (suggestion without concrete problem)
    - "This could be optimized" (no measurable defect identified)
  
  Maximum: 2 concise sentences per comment
  
RULE 7 - SEVERITY CLASSIFICATION (Precise Definitions):
  critical: Security vulnerabilities (SQL injection, XSS, auth bypass, exposed credentials/tokens),
            data corruption, guaranteed crashes/panics, breaking API changes that cause failures
  
  warning:  Logic errors, potential nil panics, resource leaks (unclosed files/connections),
            race conditions, incorrect error handling, improper error propagation, off-by-one errors,
            unsafe type assertions, missing important validations
  
  info:     Minor inefficiencies, missing non-critical error checks, suboptimal patterns that
            don't affect correctness, redundant code, missing comments on complex logic

RULE 8 - CONTEXT SENSITIVITY:
  When analyzing issues, consider:
  
  âœ“ Is this debug/test code explicitly mentioned in PR context?
    â†’ If yes, be more lenient with logging, sleeps, hardcoded values
    â†’ BUT still flag actual security issues (exposed secrets, missing auth, etc.)
  
  âœ“ Is this a temporary workaround mentioned in commits?
    â†’ Flag the underlying issue but acknowledge temporary nature
    â†’ Example: "Missing input validation. Add before production deployment."
  
  âœ“ Is the "issue" actually the intended behavior?
    â†’ Check PR title/description first before flagging
    â†’ Example: PR says "added verbose logging for debugging" â†’ don't flag verbose logs
  
  âœ— Never use PR context as excuse to ignore genuine defects
    â†’ Intentional doesn't mean correct
    â†’ Debug code can still have security flaws worth fixing

RULE 9 - OUTPUT FORMAT (Strict JSON Schema):
  âœ“ MUST be valid JSON with no markdown formatting
  âœ“ Summary format: "Found X critical, Y warning, Z info issue(s)" (use exact counts)
  âœ“ If no issues: {"summary": "No issues detected", "comments": []}
  âœ— NEVER include markdown code fences, extra text, or explanations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OUTPUT JSON SCHEMA (No markdown, no extra text)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "summary": "Found <count> critical, <count> warning, <count> info issue(s)" | "No issues detected",
  "comments": [
    {
      "file": "relative/path/to/file.go",
      "line": 42,
      "layer": "security|bug|lint|performance|architecture",
      "message": "<Problem>. <Fix>.",
      "severity": "critical|warning|info"
    }
  ]
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANALYSIS STRATEGY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Read PR Context first to understand developer intent
2. Identify all Change Blocks in the files
3. For each change:
   a. Check if it's intentional debug/test code from PR context
   b. Analyze for security vulnerabilities (always flag these)
   c. Check for logic errors and bugs
   d. Verify error handling and edge cases
   e. Look for resource leaks and race conditions
4. Use complete file content to verify:
   - Type compatibility
   - Function signatures
   - Imported dependencies
   - Surrounding context
5. Cross-reference with dependency files for interface validation
6. Generate comments only for genuine defects

REMEMBER: You are a DEFECT DETECTOR with context awareness.
- Understand developer intent, but review the actual code
- Flag real problems, not intentional debugging code
- Use severity appropriately based on actual risk
- Silence on correct code is correct behavior

BEGIN ANALYSIS NOW.
`, prContextSection, changedContent, depsContent, repoStructure, layers)
}

func buildPRContextSummary(prContext models.PRContext) string {
	var b strings.Builder
	if prContext.Title != "" {
		b.WriteString(prContext.Title)
	}
	if prContext.Body != "" {
		b.WriteString(prContext.Body)
	}
	for _, msg := range prContext.CommitMessages {
		b.WriteString(msg)
	}
	return b.String()
}

// RunChunkReview reviews a single chunk of files with scoped dependencies.
// It adds chunk metadata and cross-chunk context to the prompt.
func RunChunkReview(ctx context.Context, client *http.Client, chunkIndex int, chunkTotal int,
	chunkFiles map[string]string, chunkDiff string, crossRefs []string,
	dependencies map[string]string, settings models.RepoSettings,
	repoStructure string, apiKey string, prContext models.PRContext,
) (*models.ReviewResult, error) {

	// Filter out documentation files
	reviewableFiles := filterReviewableFiles(chunkFiles)
	reviewableDeps := filterReviewableFiles(dependencies)

	if len(reviewableFiles) == 0 {
		return &models.ReviewResult{
			Summary:  "No reviewable code files in this chunk",
			Comments: []models.ReviewComment{},
		}, nil
	}

	// Build prompt with chunk awareness
	prompt := buildPrompt(chunkDiff, reviewableFiles, reviewableDeps, settings, repoStructure, prContext)

	// Inject chunk metadata and cross-chunk context at the start of the prompt
	var chunkHeader strings.Builder
	chunkHeader.WriteString(fmt.Sprintf("NOTE: You are reviewing chunk %d of %d.\n", chunkIndex, chunkTotal))

	// Collect directory names for this chunk
	dirSet := make(map[string]bool)
	for path := range reviewableFiles {
		dirSet[filepath.Dir(path)] = true
	}
	dirs := make([]string, 0, len(dirSet))
	for d := range dirSet {
		dirs = append(dirs, d)
	}
	sort.Strings(dirs)
	chunkHeader.WriteString(fmt.Sprintf("This chunk covers: %s\n", strings.Join(dirs, ", ")))

	if len(crossRefs) > 0 {
		chunkHeader.WriteString("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
		chunkHeader.WriteString("ARCHITECTURAL CONTEXT: Cross-Chunk Dependencies\n")
		chunkHeader.WriteString("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
		chunkHeader.WriteString("Files in THIS chunk depend on files being reviewed in OTHER chunks:\n")
		for _, ref := range crossRefs {
			chunkHeader.WriteString(fmt.Sprintf("  - %s\n", ref))
		}
		chunkHeader.WriteString("\nIf you detect that changes in this chunk could break or conflict with\n")
		chunkHeader.WriteString("these external dependencies, flag it as an ARCHITECTURAL issue.\n\n")
	}

	prompt = chunkHeader.String() + prompt

	// Simplified Prompt Summary Logging (shows exactly what context is being used)
	fmt.Printf("ğŸ” [Chunk Context] Processing %d changed files:\n", len(reviewableFiles))
	for _, f := range getFileKeys(reviewableFiles) {
		fmt.Printf("   + %s (%d chars)\n", f, len(reviewableFiles[f]))
	}
	if len(reviewableDeps) > 0 {
		fmt.Printf("ğŸ” [Code Graph] Including %d project dependencies:\n", len(reviewableDeps))
		for _, d := range getFileKeys(reviewableDeps) {
			// Show a tiny preview of the dependency summary/code
			preview := "Graph Context"
			if !strings.HasPrefix(reviewableDeps[d], "CONTEXT GRAPH") {
				lines := strings.Split(reviewableDeps[d], "\n")
				if len(lines) > 2 {
					preview = lines[1] // Usually shows "resolves: ..." or First line of snippet
				}
			}
			fmt.Printf("   ğŸ”— %s (%s)\n", d, preview)
		}
	}
	if len(crossRefs) > 0 {
		fmt.Printf("ğŸ”— [Cross-Chunk] Known boundaries: %s\n", strings.Join(crossRefs, ", "))
	}
	fmt.Println("--------------------------------------------------------------------------------")

	// RAW PROMPT LOGGING (requested by user for full transparency)
	fmt.Println("\nğŸ“œ [RAW LLM PROMPT START]")
	fmt.Println(prompt)
	fmt.Println("ğŸ“œ [RAW LLM PROMPT END]")

	fmt.Println("--------------------------------------------------------------------------------")

	// Execute LLM call (same API logic as RunReview)
	reqBody := map[string]interface{}{
		"contents": []map[string]interface{}{
			{
				"parts": []map[string]string{
					{"text": prompt},
				},
			},
		},
		"generationConfig": map[string]interface{}{
			"responseMimeType": "application/json",
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %v", err)
	}

	url := fmt.Sprintf("%s?key=%s", geminiURL, apiKey)
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %v", err)
	}
	req.Header.Set("Content-Type", "application/json")

	if client == nil {
		client = &http.Client{Timeout: 60 * time.Second}
	}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("chunk %d/%d LLM request failed: %v", chunkIndex, chunkTotal, err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("chunk %d/%d LLM returned status %d: %s", chunkIndex, chunkTotal, resp.StatusCode, string(body))
	}

	var geminiResp struct {
		Candidates []struct {
			Content struct {
				Parts []struct {
					Text string `json:"text"`
				} `json:"parts"`
			} `json:"content"`
		} `json:"candidates"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&geminiResp); err != nil {
		return nil, fmt.Errorf("failed to decode chunk %d response: %v", chunkIndex, err)
	}

	if len(geminiResp.Candidates) == 0 || len(geminiResp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("chunk %d LLM returned empty response", chunkIndex)
	}

	responseText := geminiResp.Candidates[0].Content.Parts[0].Text

	var result models.ReviewResult
	if err := json.Unmarshal([]byte(responseText), &result); err != nil {
		var comments []models.ReviewComment
		if errArray := json.Unmarshal([]byte(responseText), &comments); errArray == nil {
			result.Comments = comments
			result.Summary = fmt.Sprintf("Chunk %d/%d: Automated review comments", chunkIndex, chunkTotal)
		} else {
			return nil, fmt.Errorf("failed to unmarshal chunk %d response: %v", chunkIndex, err)
		}
	}

	fmt.Printf("âœ… [CHUNK %d/%d] Found %d comments\n", chunkIndex, chunkTotal, len(result.Comments))
	return &result, nil
}

// ConsolidateResults merges results from multiple chunks into a single ReviewResult.
// Deduplicates comments by (file, line, message) to avoid repeats across overlapping context.
func ConsolidateResults(results []*models.ReviewResult) *models.ReviewResult {
	if len(results) == 0 {
		return &models.ReviewResult{
			Summary:  "No issues detected",
			Comments: []models.ReviewComment{},
		}
	}
	if len(results) == 1 {
		return results[0]
	}

	// Deduplicate by (file, line, truncated message)
	type commentKey struct {
		File    string
		Line    int
		MsgHash string
	}

	seen := make(map[commentKey]bool)
	var allComments []models.ReviewComment
	var summaries []string

	for _, r := range results {
		if r == nil {
			continue
		}
		if r.Summary != "" {
			summaries = append(summaries, r.Summary)
		}
		for _, c := range r.Comments {
			// Use first 80 chars of message as hash to catch near-dupes
			msgHash := c.Message
			if len(msgHash) > 80 {
				msgHash = msgHash[:80]
			}
			key := commentKey{File: c.File, Line: c.Line, MsgHash: msgHash}
			if !seen[key] {
				seen[key] = true
				allComments = append(allComments, c)
			}
		}
	}

	// Build consolidated summary
	critCount, warnCount, infoCount := 0, 0, 0
	for _, c := range allComments {
		switch c.Severity {
		case "critical":
			critCount++
		case "warning":
			warnCount++
		case "info":
			infoCount++
		}
	}

	summary := fmt.Sprintf("Found %d critical, %d warning, %d info issue(s) across %d chunks",
		critCount, warnCount, infoCount, len(results))
	if len(allComments) == 0 {
		summary = "No issues detected"
	}

	fmt.Printf("\nğŸ”„ [Consolidation] %d chunks â†’ %d unique comments (deduped from %d total)\n",
		len(results), len(allComments), countTotalComments(results))

	return &models.ReviewResult{
		Summary:  summary,
		Comments: allComments,
	}
}

func countTotalComments(results []*models.ReviewResult) int {
	total := 0
	for _, r := range results {
		if r != nil {
			total += len(r.Comments)
		}
	}
	return total
}
